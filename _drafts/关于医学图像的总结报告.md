涉及哪些疾病？采用什么方法？达到什么效果？
|Paper|Diseases|Method|Performance|Problems|
| --- |---|---|---|---|
| Yang, S., Liu, X., Zheng, Z., Wang, W., & Ma, X. (2021). Fusing Medical Image Features and Clinical Features with Deep Learning for Computer-Aided Diagnosis. http://arxiv.org/abs/2103.05855 | Alzheimer’s disease diagnosis, mild cognitive impairment converter prediction and hepatic microvascular invasion diagnosis|The paper proposes a novel deep learning-based method for fusing Magnetic Resonance Imaging (MRI)/Computed To-mography (CT) images and clinical information for diagnostic tasks. Two paths of neural layers are performed to extract image features and clinical features, respectively, and at the same time clinical features are employed as the attention to guide the extraction of image features. Finally, these two modalities of features are concatenated to make decisions. | The encouraging experimental results prove the values of the image feature extraction guided by clinical features and the concatenation of two modalities of features for classification, which improve the performance of diagnosis effectively and stably.|What are clinical features look like? five-stage? seven-stage?|
|Liu, W., Liu, X., Li, H., Li, M., Zhao, X., & Zhu, Z. (2021). Integrating Lung Parenchyma Segmentation and Nodule Detection with Deep Multi-Task Learning. IEEE Journal of Biomedical and Health Informatics, 25(8), 3073–3081. https://doi.org/10.1109/JBHI.2021.3053023 | Lung Parenchyma Segmentation and Nodule Detection|This paper proposes a deep multi-task learning (MTL) approach to integrate these tasks for better lung nodule detection. First, lung parenchyma segmentation is used as the attention module and is combined with nodule detection in a single deep network. Second, lung nodule detection is performed in an anchor-free manner by dividing it into two subtasks, nodule center identification and nodule size regression. Third, a novel pyramid dilated convolution block (PDCB) is proposed to utilize the advantage of dilated convolution and tackle its gridding problem for better lung parenchyma segmentation.|We evaluate the proposed approach on the commonly used Lung Nodule Analysis 2016 (LUNA16) dataset. The experimental results show the value of our contributions and demonstrate that our approach can yield significant improvements compared with state-of-the-art counterparts.|
| Boumaraf, S., Liu, X., Wan, Y., Zheng, Z., Ferkous, C., Ma, X., Li, Z., & Bardou, D. (2021). Conventional machine learning versus deep learning for magnification dependent histopathological breast cancer image classification: A comparative study with visual explanation. Diagnostics, 11(3). https://doi.org/10.3390/diagnostics11030528 | Magnification Dependent Histopathological Breast Cancer Image Classification|We compare the performance of conventional machine learning (CML) against deep learning (DL)-based methods. We also provide a visual interpretation for the task of classifying breast cancer in histopathological images. For CML-based methods, we extract a set of handcrafted features using three feature extractors and fuse them to get image representation that would act as an input to train five classical classifiers. For DL-based methods, we adopt the transfer learning approach to the well-known VGG-19 deep learning architecture, where its pre-trained version on the large scale ImageNet, is block-wise fine-tuned on histopathological images. | The achieved results show that DL methods outperform CML approaches where we reached an accuracy between 94.05% and 98.13% for the binary classification and between 76.77% and 88.95% for the eight-class classification, while for DL approaches, the accuracies range from 85.65% to 89.32% for the binary classification and from 63.55% to 69.69% for the eight-class classification. |
| Boumaraf, S., Liu, X., Zheng, Z., Ma, X., & Ferkous, C. (2021). A new transfer learning based approach to magnification dependent and independent classification of breast cancer in histopathological images. Biomedical Signal Processing and Control, 63(September 2020), 102192. https://doi.org/10.1016/j.bspc.2020.102192|Automated classification of breast cancer from histopathological images, including magnification dependent (MD) and magnification independent (MI) binary and eight-class classifications|Using global contrast normalization (GCN) based on the target’s data values and three-fold data augmentation on training data, we apply the deep neural network ResNet-18, which is pre-trained on ImageNet, and then design transfer learning method to refine the network on histopathological images, which is based on block-wise fine-tuning strategy by making the last two residual blocks more task-specific to the target data through resuming backpropagation on them and we freeze the remaining initial blocks in the deep network model.|The experimental results of MD and MI binary and eight-class classifications on the publicly available BreaKHis dataset demonstrate that our approach is promising and effective, outperforming recent state-of-the-art MD and MI counterparts by a fair margin.|
| Boumaraf, S., Liu, X., Ferkous, C., & Ma, X. (2020). A New Computer-Aided Diagnosis System with Modified Genetic Feature Selection for BI-RADS Classification of Breast Masses in Mammograms. BioMed Research International, 2020. https://doi.org/10.1155/2020/7695207 | BI-RADS(Breast Imaging Reporting and Data System) Classification of Breast Masses in Mammograms|The mass regions are first enhanced by means of histogram equalization and then semiautomatically segmented based on the region growing technique. A total of 130 handcrafted BI-RADS features are then extracted from the shape, margin, and density of each mass, together with the mass size and the patient’s age, as mentioned in BI-RADS mammography. Then, a modified feature selection method based on the genetic algorithm (GA) is proposed to select the most clinically significant BI-RADS features. Finally, a back-propagation neural network (BPN) is employed for classification, and its accuracy is used as the fitness in GA.|Our system achieves classification accuracy, positive predictive value, negative predictive value, and Matthews correlation coefficient of 84.5%, 84.4%, 94.8%, and 79.3%, respectively. |
|Liu, W., Ren, Y., & Li, H. (2020). URDNet: A Unified Regression Network for GGO Detection in Lung CT Images. Wireless Communications and Mobile Computing, 2020. https://doi.org/10.1155/2020/8862353 | GGO(ground-glass opacity) Detection in Lung CT Images | We consider GGO detection as a multitarget regression problem to focus on the location of GGO. Furthermore, to capture multiscale information, we introduce a backbone network which is a contracting-expanding structure similar to 2D U-net, but we inject the source CT inputs into each layer in the contracting pathway to prevent source information loss at different scales. At last, we propose a two-stage training method for URDNet. In the first stage, the backbone of the network for feature extraction is trained, and in the second, the overall URDNet is fine-tuned based on the previous pretrained weights. By using this training method in conjunction with data augmentation and hard negative mining techniques, our URDNet can be effectively trained even on a small amount of annotated CT images.| We evaluate the proposed method on the LIDC-IDRI dataset. It achieves the sensitivity of 90.8% with only 1 false positive per scan. Experimental results show that our detection method achieves the superior detection performance over the state-of-the-art methods. Due to its simplicity and effective, URDNet can be easier to apply to medical IoT systems for improving the efficiency of overall health systems.| 
|Han, G., Liu, X., Zhang, H., Zheng, G., Soomro, N. Q., Wang, M., & Liu, W. (2019). Hybrid resampling and multi-feature fusion for automatic recognition of cavity imaging sign in lung CT. Future Generation Computer Systems, 99, 558–570. https://doi.org/10.1016/j.future.2019.05.009|Automatic recognition of cavity imaging signs in lung computed tomography(CT) images (lung tuberculosis and cancers)|The hybrid resampling includes multi-receptive-field and multi-window settings: the former reduces the risk of missing small or large cavities, the latter reserves context information of multiply CT windows more compactly. For multi-feature fusion, we compress CNN-HOG(histograms of oriented gradients) features by principal components analysis (PCA) algorithm and combine them with LBP(local binary pattern) feature. Finally, we use the fused feature to train a support vector machine (SVM) model for improving classification performance.|We evaluate our method on the cavity samples from LIDC-IDRI and LISS publicly available dataset of chest CT scans, which contains 167 cavities in 164 CT images. The experimental results show that fused feature has better discriminative capability than any single feature, and has the highest FS score (0.1472 vs 0.1136) in the group with sensitivity greater than 0.8.|
|Li, H., Liu, X., Boumaraf, S., Liu, W., Gong, X., & Ma, X. (2019). A NEW THREE-STAGE CURRICULUM LEARNING APPROACH TO DEEP NETWORK BASED LIVER TUMOR SEGMENTATION Beijing Lab of Intelligent Information Technology , School of Computer Science , Beijing Institute of National Cancer Center / National Clinical Research Center. 1–5.|Automatic segmentation of liver tumors|The learning in the first stage is performed on the whole input to obtain an initial deep network for tumor segmentation.Then the second stage of learning focuses the strengthening of tumor specific features by continuing training the network on the tumor patches. Finally, we retrain the network on the whole input in the third stage, in order that the tumor specific features and the global context can be integrated ideally under the segmentation objective.|We evaluated our approach on the 2017 MICCAI Liver Tumor Segmentation challenge dataset. In the experiments, our approach exhibits significant improvement compared with the commonly used cascaded counterpart.|What is Preprocessing doing? Why do this?|
|Ma, L., Liu, X., & Fei, B. (2020). A multi-level similarity measure for the retrieval of the common CT imaging signs of lung diseases. Medical and Biological Engineering and Computing, 58(5), 1015–1029. https://doi.org/10.1007/s11517-020-02146-4 | Retrieval of the common CT imaging signs of lung diseases|we propose a multi-level method to measure the similarity between the CISLs(The common CT imaging signs of lung diseases). The similarity at multiple levels (low-level visual scale, mid-level attribute scale, and high-level semantic scale) is calculated and combined in a weighted sum form as the final similarity. | The effectiveness of the proposed similarity measure method is evaluated on a dataset of 511 lung CT images from clinical patients for CISLs retrieval. It can achieve about 80% precision and take only 3.6 ms for the retrieval process.|
|Han, G., Liu, X., Soomro, N. Q., Sun, J., Zhao, Y., Zhao, X., & Zhou, C. (2017). Empirical Driven Automatic Detection of Lobulation Imaging Signs in Lung CT. BioMed Research International, 2017. https://doi.org/10.1155/2017/3842659|||